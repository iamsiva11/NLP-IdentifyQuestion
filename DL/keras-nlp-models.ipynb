{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(csv_file):\n",
    "    names = [\"question\", \"type\"]\n",
    "    dataset_all = pd.read_csv(csv_file,names=names)\n",
    "    return dataset_all\n",
    "\n",
    "dataset_all = load_data('nikiai_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question     type\n",
       "0  how did serfdom develop in and then leave russ...  unknown\n",
       "1  what films featured the character popeye doyle ?      what\n",
       "2  how can i find a list of celebrities ' real na...  unknown\n",
       "3  what fowl grabs the spotlight after the chines...     what\n",
       "4                   what is the full form of .com ?      what"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek into the Data\n",
    "dataset_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape - (1483, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape - {}\").format(dataset_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preapre data - get features and labels\n",
    "def preapre_data(dataset_all):\n",
    "    dataset=dataset_all.values\n",
    "    X_Train = dataset[:,0]\n",
    "    Y_Train = dataset[:,1]\n",
    "    return  X_Train, Y_Train\n",
    "\n",
    "X_Train, Y_Train = preapre_data(dataset_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how did serfdom develop in and then leave russia ? '\n",
      " 'what films featured the character popeye doyle ? '\n",
      " \"how can i find a list of celebrities ' real names ? \"\n",
      " 'what fowl grabs the spotlight after the chinese year of the monkey ? '\n",
      " 'what is the full form of .com ? '\n",
      " 'what contemptible scoundrel stole the cork from my lunch ? '\n",
      " \"what team did baseball 's st. louis browns become ? \"\n",
      " 'what is the oldest profession ? ' 'what are liver enzymes ? '\n",
      " 'name the scar-faced bounty hunter of the old west . ']\n",
      "['unknown' 'what' 'unknown' 'what' 'what' 'what' 'what' 'what' 'what'\n",
      " 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print X_Train[:10]\n",
    "print Y_Train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "def remove_questionmark(slist):\n",
    "    new_x = []\n",
    "    for x in slist:\n",
    "         new_x.append(x.replace(\"?\",\"\"))\n",
    "    return new_x\n",
    "    \n",
    "X_Train = remove_questionmark(X_Train)\n",
    "X_Train = map(str.rstrip,X_Train)\n",
    "\n",
    "from string import digits\n",
    "\n",
    "def remove_numbers(slist):\n",
    "    res = map(lambda x: x.translate(None, digits), slist)\n",
    "    return res\n",
    "\n",
    "X_Train = remove_numbers(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_lables(Y_Train):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y_Train)\n",
    "    encoded_y = encoder.transform(Y_Train)\n",
    "    return  encoder, encoded_y\n",
    "\n",
    "encoder, encoded_y = encode_lables(Y_Train)\n",
    "encoded_y = encoded_y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NB_WORDS = 5000\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "def tokenise_padding(X_Train):\n",
    "    #Construct a tokenizer object, initialized with the number of total terms we want.\n",
    "    tok = Tokenizer(MAX_NB_WORDS)\n",
    "    tok.fit_on_texts(X_Train)\n",
    "    X_Train = tok.texts_to_sequences(X_Train)\n",
    "    X_Train_pad = pad_sequences(X_Train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return  tok, X_Train_pad\n",
    "\n",
    "tok, X_Train_pad = tokenise_padding(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test data preapre\n",
    "X_Test=[\"Name 11 famous martyrs\",\n",
    "\"Who was the inventor of silly putty ?\",\n",
    "\"What 1920s cowboy star rode Tony the Wonder Horse ?\",\n",
    "\"How many villi are found in the small intestine ?\",\n",
    "\"does this hose have one ?\",\n",
    "\"What is your name?\",\n",
    "\"When is the show happening?\",\n",
    "\"Is there a cab available for airport?\",\n",
    "\"What time does the train leave\",\n",
    "\"when was the last time you did something for the first time\" ]\n",
    "\n",
    "def preapre_testData(X_Test,tok):\n",
    "    #X_Test= map(lambda x:x.lower,X_Test)\n",
    "    X_Test = map(str.lower,X_Test)\n",
    "    X_Test = remove_questionmark(X_Test)\n",
    "    X_Test = map(str.rstrip,X_Test)\n",
    "    X_Test = remove_numbers(X_Test)\n",
    "    #MAX_SEQUENCE_LENGTH = 50\n",
    "    X_Test = tok.texts_to_sequences(X_Test)\n",
    "    X_Test_pad = pad_sequences(X_Test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return X_Test_pad\n",
    "\n",
    "X_Test_pad = preapre_testData(X_Test, tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 50, 32)        160000      embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50, 32)        0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "simplernn_1 (SimpleRNN)          (None, 16)            784         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           4352        simplernn_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 256)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 256)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 5)             1285        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 5)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 166,421\n",
      "Trainable params: 166,421\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Activation\n",
    "from keras.layers import  Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "# from keras.layers.recurrent import  LSTM, GRU\n",
    "# from keras.layers.convolutional import Convolution1D\n",
    "# from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "#Model Architecture\n",
    "#Define the model\n",
    "def model_vanillaRNN():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, 32, input_length=MAX_SEQUENCE_LENGTH))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(SimpleRNN(16, return_sequences=False))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "rnn1 = model_vanillaRNN()\n",
    "print(rnn1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1483/1483 [==============================] - 0s - loss: 1.4281 - acc: 0.3898     \n",
      "Epoch 2/20\n",
      "1483/1483 [==============================] - 0s - loss: 1.3445 - acc: 0.4208     \n",
      "Epoch 3/20\n",
      "1483/1483 [==============================] - 0s - loss: 1.0920 - acc: 0.5374     \n",
      "Epoch 4/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.7729 - acc: 0.7350     \n",
      "Epoch 5/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.5689 - acc: 0.8045     \n",
      "Epoch 6/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.4192 - acc: 0.8584     \n",
      "Epoch 7/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.3287 - acc: 0.8982     \n",
      "Epoch 8/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.2395 - acc: 0.9225     \n",
      "Epoch 9/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.1794 - acc: 0.9420     \n",
      "Epoch 10/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.1391 - acc: 0.9575     \n",
      "Epoch 11/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0931 - acc: 0.9804     \n",
      "Epoch 12/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0679 - acc: 0.9852     \n",
      "Epoch 13/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0461 - acc: 0.9892     \n",
      "Epoch 14/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0335 - acc: 0.9912     \n",
      "Epoch 15/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0276 - acc: 0.9926     \n",
      "Epoch 16/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0236 - acc: 0.9933     \n",
      "Epoch 17/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0188 - acc: 0.9953     \n",
      "Epoch 18/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0095 - acc: 0.9980     \n",
      "Epoch 19/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0042 - acc: 1.0000     \n",
      "Epoch 20/20\n",
      "1483/1483 [==============================] - 0s - loss: 0.0035 - acc: 0.9993     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e96a9e290>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the Model\n",
    "rnn1.fit(X_Train_pad, encoded_y, batch_size=32, nb_epoch=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 50, 32)        160000      embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 50, 32)        0           embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 50, 32)        3104        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 25, 32)        0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100)           53200       maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 5)             505         lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 5)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 216,809\n",
      "Trainable params: 216,809\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.recurrent import  LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "def model_lstm_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, 32, input_length=MAX_SEQUENCE_LENGTH))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_length=2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_lstm1 = model_lstm_cnn()\n",
    "print(cnn_lstm1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1483/1483 [==============================] - 1s - loss: 1.4138 - acc: 0.4032     \n",
      "Epoch 2/20\n",
      "1483/1483 [==============================] - 1s - loss: 1.0637 - acc: 0.5873     \n",
      "Epoch 3/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.6244 - acc: 0.7903     \n",
      "Epoch 4/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.4597 - acc: 0.8422     \n",
      "Epoch 5/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.3527 - acc: 0.8833     \n",
      "Epoch 6/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.2652 - acc: 0.9184     \n",
      "Epoch 7/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.1839 - acc: 0.9568     \n",
      "Epoch 8/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.1404 - acc: 0.9629     \n",
      "Epoch 9/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.1002 - acc: 0.9777     \n",
      "Epoch 10/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0980 - acc: 0.9737     \n",
      "Epoch 11/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0699 - acc: 0.9791     \n",
      "Epoch 12/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0591 - acc: 0.9838     \n",
      "Epoch 13/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0487 - acc: 0.9865     \n",
      "Epoch 14/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0394 - acc: 0.9852     \n",
      "Epoch 15/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0370 - acc: 0.9879     \n",
      "Epoch 16/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0266 - acc: 0.9926     \n",
      "Epoch 17/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0200 - acc: 0.9960     \n",
      "Epoch 18/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0169 - acc: 0.9946     \n",
      "Epoch 19/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0098 - acc: 0.9973     \n",
      "Epoch 20/20\n",
      "1483/1483 [==============================] - 1s - loss: 0.0080 - acc: 0.9973     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e77235310>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_lstm1.fit(X_Train_pad, encoded_y, batch_size=32, nb_epoch=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting dataset for Evaluation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(X_Train_pad, encoded_y, random_state=33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 736/1112 [==================>...........] - ETA: 0s[0.0005104391349972856, 1.0]\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Model 1 - Evaluation\n",
    "def evaluate_model(model, train, test):\n",
    "    scores = model.evaluate(train, test )\n",
    "    print scores\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "evaluate_model(rnn1, split_X_test, split_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056/1112 [===========================>..] - ETA: 0s[0.0018669994717142244, 1.0]\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cnn_lstm1, split_X_test, split_y_test)\n",
    "\n",
    "# #Model 2 - Evaluation\n",
    "# scores = cnn_lstm1.evaluate(split_X_train, split_y_train )\n",
    "# print scores\n",
    "# print(\"%s: %.2f%%\" % (cnn_lstm1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n",
      "['unknown' 'who' 'what' 'unknown' 'affirmation' 'who' 'when' 'affirmation'\n",
      " 'when' 'unknown']\n"
     ]
    }
   ],
   "source": [
    "def predict_classes(model, X_Test):\n",
    "    res = rnn1.predict_classes(X_Test)\n",
    "    print encoder.inverse_transform(res)\n",
    "\n",
    "#Model 1 Predictions\n",
    "predict_classes(rnn1, X_Test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n",
      "['unknown' 'who' 'what' 'unknown' 'affirmation' 'who' 'when' 'affirmation'\n",
      " 'when' 'unknown']\n"
     ]
    }
   ],
   "source": [
    "#Model 2 Predictions\n",
    "predict_classes(cnn_lstm1, X_Test_pad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
